

<!DOCTYPE html>
<html class="writer-html5" lang="zh-CN" >
<head>
  <meta charset="utf-8" />
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  
  <title>2020 &mdash; Robust CE 0.1 文档</title>
  

  
  <link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />

  
  

  
  

  

  
  <!--[if lt IE 9]>
    <script src="../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../../" src="../../_static/documentation_options.js"></script>
        <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
        <script src="../../_static/jquery.js"></script>
        <script src="../../_static/underscore.js"></script>
        <script src="../../_static/doctools.js"></script>
        <script src="../../_static/translations.js"></script>
    
    <script type="text/javascript" src="../../_static/js/theme.js"></script>

    
    <link rel="author" title="关于这些文档" href="../../about.html" />
    <link rel="index" title="索引" href="../../genindex.html" />
    <link rel="search" title="搜索" href="../../search.html" />
    <link rel="next" title="2021" href="../2021/contents.html" />
    <link rel="prev" title="Paper" href="../index.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../../contents.html" class="icon icon-home"> Robust CE
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="在文档中搜索" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Contents:</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../../about.html">关于</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../CE.html">Counterfactual Explanations</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="../index.html">Paper</a><ul class="current">
<li class="toctree-l2 current"><a class="current reference internal" href="#">2020</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#id2">二级标题</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#id3">三级标题</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../2021/contents.html">2021</a></li>
</ul>
</li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../contents.html">Robust CE</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          

















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../../contents.html" class="icon icon-home"></a> &raquo;</li>
        
          <li><a href="../index.html">Paper</a> &raquo;</li>
        
      <li>2020</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
          
            <a href="../../_sources/Paper/2020/contents.md.txt" rel="nofollow"> 查看页面源码</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="id1">
<h1>2020<a class="headerlink" href="#id1" title="永久链接至标题">¶</a></h1>
<p>​
秋风吹不尽，总是玉关情。
​</p>
<div class="section" id="id2">
<h2>二级标题<a class="headerlink" href="#id2" title="永久链接至标题">¶</a></h2>
<p>​
​</p>
<div class="section" id="id3">
<h3>三级标题<a class="headerlink" href="#id3" title="永久链接至标题">¶</a></h3>
<p>​
​</p>
<div class="section" id="id4">
<h4>四级标题<a class="headerlink" href="#id4" title="永久链接至标题">¶</a></h4>
<ul class="simple">
<li><p>Interpretation of Neural Networks is Fragile</p>
<ul>
<li><p>作者</p>
<ul>
<li><p>Amirata Ghorbani, Abubakar Abid, James Zou</p></li>
</ul>
</li>
<li><p>论文出处</p>
<ul>
<li><p>AAAI 2019</p></li>
</ul>
</li>
<li><p>时间</p>
<ul>
<li><p>2018</p></li>
</ul>
</li>
<li><p>链接</p>
<ul>
<li><p><a class="reference external" href="https://arxiv.org/abs/1710.10547">https://arxiv.org/abs/1710.10547</a></p></li>
</ul>
</li>
<li><p>摘要</p>
<ul>
<li><p>In order for machine learning to be deployed and trusted in many applications, it is crucial to be able to reliably explain why the machine learning algorithm makes certain predictions. For example, if an algorithm classifies a given pathology image to be a malignant tumor, then the doctor may need to know which parts of the image led the algorithm to this classification. How to interpret black-box predictors is thus an important and active area of research. A fundamental question is: how much can we trust the interpretation itself? In this paper, we show that interpretation of deep learning predictions is extremely fragile in the following sense: two perceptively indistinguishable inputs with the same predicted label can be assigned very different interpretations. We systematically characterize the fragility of several widely-used feature-importance interpretation methods (saliency maps, relevance propagation, and DeepLIFT) on ImageNet and CIFAR-10. Our experiments show that even small random perturbation can change the feature importance and new systematic perturbations can lead to dramatically different interpretations without changing the label. We extend these results to show that interpretations based on exemplars (e.g. influence functions) are similarly fragile. Our analysis of the geometry of the Hessian matrix gives insight on why fragility could be a fundamental challenge to the current interpretation approaches.</p></li>
</ul>
</li>
</ul>
</li>
</ul>
</div>
</div>
</div>
</div>


           </div>
           
          </div>
          <footer>
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
        <a href="../2021/contents.html" class="btn btn-neutral float-right" title="2021" accesskey="n" rel="next">下一页 <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
        <a href="../index.html" class="btn btn-neutral float-left" title="Paper" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> 上一页</a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>
        &#169; 版权所有 2021, Hongyu Qiu.

    </p>
  </div>
    
    
    
    利用 <a href="https://www.sphinx-doc.org/">Sphinx</a> 构建，使用了 
    
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">主题</a>
    
    由 <a href="https://readthedocs.org">Read the Docs</a>开发. 

</footer>
        </div>
      </div>

    </section>

  </div>
  

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>